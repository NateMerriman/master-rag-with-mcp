# MCP Crawl4AI RAG Server Configuration

# Required - OpenAI API Configuration
# Get your Open AI API Key by following these instructions -
# https://help.openai.com/en/articles/4936850-where-do-i-find-my-openai-api-key
# This is for the embedding model - text-embed-small-3 will be used
OPENAI_API_KEY=

# Required - Supabase Configuration
# Get your SUPABASE_URL from the API section of your Supabase project settings -
# https://supabase.com/dashboard/project/<your project ID>/settings/api
SUPABASE_URL=

# Get your SUPABASE_SERVICE_KEY from the API section of your Supabase project settings -
# https://supabase.com/dashboard/project/<your project ID>/settings/api
# On this page it is called the service_role secret.
SUPABASE_SERVICE_KEY=

# Server Configuration
# The transport for the MCP server - either 'sse' or 'stdio' (defaults to sse if left empty)
TRANSPORT=
# Host to bind to if using sse as the transport (leave empty if using stdio)
HOST=
# Port to listen on if using sse as the transport (leave empty if using stdio)
PORT=

# Optional - Existing Features
# The LLM you want to use for contextual embeddings (contextual retrieval)
# Leave this blank if you do not want to use contextual embeddings
# Generally this is a very cheap and fast LLM like gpt-4o-mini
MODEL_CHOICE=

# =============================================================================
# RAG Strategy Configuration (all default to false for backward compatibility)
# Enable advanced strategies individually or in combination
# =============================================================================

# Contextual Embeddings - Enhances chunk embeddings with document context
# Requires MODEL_CHOICE to be set
USE_CONTEXTUAL_EMBEDDINGS=false
CONTEXTUAL_MODEL=gpt-3.5-turbo

# Enhanced Hybrid Search - Advanced RRF algorithms and query processing  
USE_HYBRID_SEARCH_ENHANCED=false

# Agentic RAG - Specialized code extraction and search capabilities
USE_AGENTIC_RAG=false

# Cross-Encoder Reranking - Local result reordering for improved quality
USE_RERANKING=false
RERANKING_MODEL=cross-encoder/ms-marco-MiniLM-L-6-v2

# Performance Tuning
MAX_RERANKING_RESULTS=20
RERANKING_TIMEOUT_MS=500

# =============================================================================
# Example Strategy Combinations:
# =============================================================================
# Basic enhanced search:
#   USE_RERANKING=true
#
# High-quality code search:
#   USE_CONTEXTUAL_EMBEDDINGS=true
#   USE_AGENTIC_RAG=true
#   MODEL_CHOICE=gpt-4o-mini
#
# Maximum quality (resource intensive):
#   USE_CONTEXTUAL_EMBEDDINGS=true
#   USE_RERANKING=true
#   USE_AGENTIC_RAG=true
#   MODEL_CHOICE=gpt-4o-mini